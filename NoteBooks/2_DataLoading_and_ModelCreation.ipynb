{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# install libraries\n",
    "!pip install torchmetrics --quiet\n",
    "!pip install pytorch_lightning --quiet\n",
    "!pip install tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # model creation\n",
    "import torchvision # data loaders\n",
    "from torchvision import transforms # data augmentation and normalization\n",
    "import torchmetrics # easy metric computation\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint # frequently store weights\n",
    "from pytorch_lightning.loggers import TensorBoardLogger # logging in TensorBoard\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# load drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    # Load the file as a numpy array\n",
    "    # Convert the data to float32 type\n",
    "    return np.load(path).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transforms is a set of transformations to be applied to the training data\n",
    "# transforms.ToTensor() converts the image to a tensor\n",
    "# transforms.normalize(0.49, 0.248) normalizes the tensor by subtracting the mean of 0.49 and dividing by the standard deviation of 0.248\n",
    "# transforms.RandomAffine(degrees=(-5, 5), translate=(0, 0.05), scale=(0.9, 1.1)) applies a random affine transformation to the image\n",
    "#rotating it by a random angle between -5 to 5 degrees, translating it randomly by up to 5% in both the x and y directions, and scaling it randomly between 0.9 to 1.1 times\n",
    "# transforms.RandomResizedCrop((224, 224), scale=(0.35, 1)) applies a random resized crop to the image, cropping it to a size of 224x224 with a random scale between 0.35 to 1\n",
    "\n",
    "# val_transforms is a set of transformations to be applied to the validation data\n",
    "# It has the same transformations as train_transforms, except without the random affine and random resized crop transformations\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.49, 0.248),\n",
    "    transforms.RandomAffine(degrees=(-5, 5), translate=(0, 0.05), scale=(0.9, 1.1)),\n",
    "    transforms.RandomResizedCrop((224, 224), scale=(0.35, 1))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.49, 0.248)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.DatasetFolder('/content/drive/Shareddrives/Gdrive/Dataset/Pneumonia_Detection/Processed/train/',\n",
    "                                                   loader = load_file, extensions='npy', transform=train_transforms)\n",
    "\n",
    "val_dataset = torchvision.datasets.DatasetFolder('/content/drive/Shareddrives/Gdrive/Dataset/Pneumonia_Detection/Processed/val/',\n",
    "                                                   loader = load_file, extensions='npy', transform=val_transforms)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
